{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "196ba1cc-cc51-493b-ab75-e2cc77086a85",
   "metadata": {},
   "source": [
    "# T1 - Reprise du modèle défini à la partie 1\n",
    "\n",
    "Notre modèle dimensionnel révisé comprend :\n",
    "- 2 tables de faits : FACT_SALES et FACT_INVENTORY\n",
    "- 5 dimensions : DIM_TIME, DIM_PRODUCT, DIM_CUSTOMER, DIM_GEOGRAPHY, DIM_DEPARTMENT\n",
    "\n",
    "Vérification de la faisabilité avec les données disponibles :\n",
    "- Pour FACT_SALES : Nous avons orders.csv et order_details.csv qui contiennent les données nécessaires\n",
    "- Pour FACT_INVENTORY : Nous devrons dériver cette table à partir des ventes et des capacités de stockage\n",
    "- Pour les dimensions : Nous avons les fichiers correspondants (customers.csv, products.csv, etc.)\n",
    "\n",
    "Le modèle est donc réalisable avec les données disponibles, bien que certaines mesures devront être calculées ou estimées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fb29a-964f-4d8c-aaeb-8578848a3477",
   "metadata": {},
   "source": [
    "# T2 - Importation des fichiers CSV et inspection des structures\n",
    "Commençons par importer les fichiers CSV et examiner leur structure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852bba07-1d76-471c-8245-1a5c4b0e8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299cc651-ed98-47dc-813c-01a31434cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des fichiers CSV\n",
    "addresses_df = pd.read_csv('data/addresses.csv')\n",
    "customers_df = pd.read_csv('data/customers.csv')\n",
    "departments_df = pd.read_csv('data/departments.csv')\n",
    "order_details_df = pd.read_csv('data/order_details.csv')\n",
    "orders_df = pd.read_csv('data/orders.csv')\n",
    "products_df = pd.read_csv('data/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4487c9-f24f-4e03-a306-16d89f346d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Aperçu de addresses_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4910 entries, 0 to 4909\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Address ID   4910 non-null   object\n",
      " 1   Customer ID  4910 non-null   object\n",
      " 2   Country      4910 non-null   object\n",
      " 3   City         4910 non-null   object\n",
      " 4   State        4910 non-null   object\n",
      " 5   Postal Code  4910 non-null   int64 \n",
      " 6   Region       4910 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 268.6+ KB\n",
      "None\n",
      "       Address ID Customer ID        Country             City           State  \\\n",
      "0  CG-12520_42420    CG-12520  United States        Henderson        Kentucky   \n",
      "1  DV-13045_90036    DV-13045  United States      Los Angeles      California   \n",
      "2  SO-20335_33311    SO-20335  United States  Fort Lauderdale         Florida   \n",
      "3  BH-11710_90032    BH-11710  United States      Los Angeles      California   \n",
      "4  AA-10480_28027    AA-10480  United States          Concord  North Carolina   \n",
      "\n",
      "   Postal Code Region  \n",
      "0        42420  South  \n",
      "1        90036   West  \n",
      "2        33311  South  \n",
      "3        90032   West  \n",
      "4        28027  South  \n",
      "\n",
      "=== Aperçu de customers_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 793 entries, 0 to 792\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Customer ID    793 non-null    object\n",
      " 1   Customer Name  793 non-null    object\n",
      " 2   Segment        793 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 18.7+ KB\n",
      "None\n",
      "  Customer ID    Customer Name    Segment\n",
      "0    CG-12520      Claire Gute   Consumer\n",
      "1    DV-13045  Darrin Van Huff  Corporate\n",
      "2    SO-20335   Sean O'Donnell   Consumer\n",
      "3    BH-11710  Brosina Hoffman   Consumer\n",
      "4    AA-10480     Andrew Allen   Consumer\n",
      "\n",
      "=== Aperçu de departments_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Department        3 non-null      object\n",
      " 1   City              3 non-null      object\n",
      " 2   Storage Capacity  3 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 204.0+ bytes\n",
      "None\n",
      "        Department           City  Storage Capacity\n",
      "0        Furniture  New York City              3003\n",
      "1  Office Supplies  San Francisco              4043\n",
      "2       Technology   Philadelphia              2257\n",
      "\n",
      "=== Aperçu de order_details_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9993 entries, 0 to 9992\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Order ID    9993 non-null   object \n",
      " 1   Product ID  9993 non-null   object \n",
      " 2   Sales       9993 non-null   float64\n",
      " 3   Quantity    9993 non-null   int64  \n",
      " 4   Profit      9993 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 390.5+ KB\n",
      "None\n",
      "         Order ID       Product ID   Sales  Quantity  Profit\n",
      "0  CA-2016-152156  FUR-BO-10001798  261.96         2   41.91\n",
      "1  CA-2016-152156  FUR-CH-10000454  731.94         3  219.58\n",
      "2  CA-2016-138688  OFF-LA-10000240   14.62         2    6.87\n",
      "3  US-2015-108966  FUR-TA-10000577  957.58         5 -383.03\n",
      "4  US-2015-108966  OFF-ST-10000760   22.37         2    2.52\n",
      "\n",
      "=== Aperçu de orders_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5009 entries, 0 to 5008\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Order ID     5009 non-null   object\n",
      " 1   Order Date   5009 non-null   object\n",
      " 2   Ship Date    5009 non-null   object\n",
      " 3   Customer ID  5009 non-null   object\n",
      " 4   Address ID   5009 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 195.8+ KB\n",
      "None\n",
      "         Order ID  Order Date   Ship Date Customer ID      Address ID\n",
      "0  CA-2016-152156  2021-11-02  2021-11-05    CG-12520  CG-12520_42420\n",
      "1  CA-2016-138688  2021-06-06  2021-06-10    DV-13045  DV-13045_90036\n",
      "2  US-2015-108966  2020-10-04  2020-10-11    SO-20335  SO-20335_33311\n",
      "3  CA-2014-115812  2019-06-03  2019-06-08    BH-11710  BH-11710_90032\n",
      "4  CA-2017-114412  2022-04-09  2022-04-14    AA-10480  AA-10480_28027\n",
      "\n",
      "=== Aperçu de products_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1862 entries, 0 to 1861\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Product ID    1862 non-null   object\n",
      " 1   Department    1862 non-null   object\n",
      " 2   Sub-Category  1862 non-null   object\n",
      " 3   Product Name  1862 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 58.3+ KB\n",
      "None\n",
      "        Product ID       Department Sub-Category  \\\n",
      "0  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1  FUR-CH-10000454        Furniture       Chairs   \n",
      "2  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3  FUR-TA-10000577        Furniture       Tables   \n",
      "4  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name  \n",
      "0                  Bush Somerset Collection Bookcase  \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  \n",
      "2  Self-Adhesive Address Labels for Typewriters b...  \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  \n",
      "4                     Eldon Fold 'N Roll Cart System  \n"
     ]
    }
   ],
   "source": [
    "# Inspection des structures\n",
    "print(\"=== Aperçu de addresses_df ===\")\n",
    "print(addresses_df.info())\n",
    "print(addresses_df.head())\n",
    "print(\"\\n=== Aperçu de customers_df ===\")\n",
    "print(customers_df.info())\n",
    "print(customers_df.head())\n",
    "print(\"\\n=== Aperçu de departments_df ===\")\n",
    "print(departments_df.info())\n",
    "print(departments_df.head())\n",
    "print(\"\\n=== Aperçu de order_details_df ===\")\n",
    "print(order_details_df.info())\n",
    "print(order_details_df.head())\n",
    "print(\"\\n=== Aperçu de orders_df ===\")\n",
    "print(orders_df.info())\n",
    "print(orders_df.head())\n",
    "print(\"\\n=== Aperçu de products_df ===\")\n",
    "print(products_df.info())\n",
    "print(products_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431cd936-507c-416a-af3b-a24cc1e6857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Valeurs manquantes ===\n",
      "addresses_df ne contient pas de valeurs manquantes\n",
      "customers_df ne contient pas de valeurs manquantes\n",
      "departments_df ne contient pas de valeurs manquantes\n",
      "order_details_df ne contient pas de valeurs manquantes\n",
      "orders_df ne contient pas de valeurs manquantes\n",
      "products_df ne contient pas de valeurs manquantes\n"
     ]
    }
   ],
   "source": [
    "# Vérification des valeurs manquantes\n",
    "print(\"\\n=== Valeurs manquantes ===\")\n",
    "for df_name, df in [(\"addresses_df\", addresses_df), \n",
    "                    (\"customers_df\", customers_df),\n",
    "                    (\"departments_df\", departments_df),\n",
    "                    (\"order_details_df\", order_details_df),\n",
    "                    (\"orders_df\", orders_df),\n",
    "                    (\"products_df\", products_df)]:\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(f\"{df_name} contient des valeurs manquantes:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "    else:\n",
    "        print(f\"{df_name} ne contient pas de valeurs manquantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6565972-2339-4fce-9378-098f6cbc7272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Doublons ===\n",
      "addresses_df contient 0 doublons\n",
      "customers_df contient 0 doublons\n",
      "departments_df contient 0 doublons\n",
      "order_details_df contient 0 doublons\n",
      "orders_df contient 0 doublons\n",
      "products_df contient 0 doublons\n"
     ]
    }
   ],
   "source": [
    "# Vérification des doublons\n",
    "print(\"\\n=== Doublons ===\")\n",
    "for df_name, df in [(\"addresses_df\", addresses_df), \n",
    "                    (\"customers_df\", customers_df),\n",
    "                    (\"departments_df\", departments_df),\n",
    "                    (\"order_details_df\", order_details_df),\n",
    "                    (\"orders_df\", orders_df),\n",
    "                    (\"products_df\", products_df)]:\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"{df_name} contient {duplicates} doublons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "713f4e26-ce59-416a-af57-2577773f4f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Types de données ===\n",
      "addresses_df types:\n",
      "Address ID     object\n",
      "Customer ID    object\n",
      "Country        object\n",
      "City           object\n",
      "State          object\n",
      "Postal Code     int64\n",
      "Region         object\n",
      "dtype: object\n",
      "customers_df types:\n",
      "Customer ID      object\n",
      "Customer Name    object\n",
      "Segment          object\n",
      "dtype: object\n",
      "departments_df types:\n",
      "Department          object\n",
      "City                object\n",
      "Storage Capacity     int64\n",
      "dtype: object\n",
      "order_details_df types:\n",
      "Order ID       object\n",
      "Product ID     object\n",
      "Sales         float64\n",
      "Quantity        int64\n",
      "Profit        float64\n",
      "dtype: object\n",
      "orders_df types:\n",
      "Order ID               object\n",
      "Order Date     datetime64[ns]\n",
      "Ship Date      datetime64[ns]\n",
      "Customer ID            object\n",
      "Address ID             object\n",
      "dtype: object\n",
      "products_df types:\n",
      "Product ID      object\n",
      "Department      object\n",
      "Sub-Category    object\n",
      "Product Name    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Vérification des types de données\n",
    "print(\"\\n=== Types de données ===\")\n",
    "for df_name, df in [(\"addresses_df\", addresses_df), \n",
    "                    (\"customers_df\", customers_df),\n",
    "                    (\"departments_df\", departments_df),\n",
    "                    (\"order_details_df\", order_details_df),\n",
    "                    (\"orders_df\", orders_df),\n",
    "                    (\"products_df\", products_df)]:\n",
    "    print(f\"{df_name} types:\")\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b30758-8769-40f3-92a9-9a3ff65ebcc6",
   "metadata": {},
   "source": [
    "Après cette inspection, voici ce que nous pouvons relever :\n",
    "- Contrairement à nos suppositions, aucun des dataframes ne contient de valeurs manquantes, ce qui signifie que les données sont d'excellente qualité.\n",
    "- Aucun des dataframes ne contient de doublons, ce qui simplifie le processus de nettoyage.\n",
    "- Les dates dans orders_df (Order Date, Ship Date) sont au format string (object) et doivent être converties en format datetime pour permettre des opérations temporelles.\n",
    "- Les autres types de données semblent appropriés (les valeurs numériques sont déjà en int64 ou float64)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db80223-11a4-404d-b075-c15a024b5f5b",
   "metadata": {},
   "source": [
    "# T3 - Nettoyage des données\n",
    "Maintenant, procédons au nettoyage des données pour chaque dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfdff917-4ae2-4f20-8945-4a3ce5e5606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification et traitement des valeurs manquantes (il ne semble pas y en avoir, mais on ne sait jamais)\n",
    "# Pour addresses_df\n",
    "if addresses_df.isnull().sum().sum() > 0: # le premier .sum() donne le nombre de isNull par colonne, le second fait la somme de ces isNull\n",
    "    # Remplir les valeurs manquantes ou supprimer les lignes selon le contexte\n",
    "    addresses_df = addresses_df.dropna(subset=['Customer ID', 'City', 'State', 'Region'])\n",
    "    # Pour les autres colonnes, on peut remplir avec des valeurs par défaut\n",
    "    addresses_df['Postal Code'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Pour customers_df\n",
    "if customers_df.isnull().sum().sum() > 0:\n",
    "    # Les informations client doivent être complètes pour être exploitables, donc on supprime les lignes avec des valeurs manquantes\n",
    "    customers_df = customers_df.dropna()\n",
    "\n",
    "# Pour order_details_df\n",
    "if order_details_df.isnull().sum().sum() > 0:\n",
    "    # Vérifier les colonnes avec des valeurs manquantes\n",
    "    # Pour les valeurs numériques, on peut remplacer par 0 ou la moyenne\n",
    "    order_details_df['Quantity'].fillna(0, inplace=True)\n",
    "    order_details_df['Sales'].fillna(0, inplace=True)\n",
    "    order_details_df['Profit'].fillna(0, inplace=True)\n",
    "    # Supprimer les lignes où Product ID est manquant\n",
    "    order_details_df = order_details_df.dropna(subset=['Product ID'])\n",
    "\n",
    "# Pour products_df\n",
    "if products_df.isnull().sum().sum() > 0:\n",
    "    # Les informations produit sont essentielles, donc on supprime les lignes avec des valeurs manquantes\n",
    "    products_df = products_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db949f6c-850e-4b33-84cf-81dee560e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des doublons (les outputs de T2 n'en montrent pas, mais on ne sait jamais)\n",
    "addresses_df = addresses_df.drop_duplicates()\n",
    "customers_df = customers_df.drop_duplicates()\n",
    "departments_df = departments_df.drop_duplicates()\n",
    "order_details_df = order_details_df.drop_duplicates()\n",
    "orders_df = orders_df.drop_duplicates()\n",
    "products_df = products_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54e5f325-d77e-417d-a484-546def4d239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des dates dans orders_df\n",
    "orders_df['Order Date'] = pd.to_datetime(orders_df['Order Date'])\n",
    "orders_df['Ship Date'] = pd.to_datetime(orders_df['Ship Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "349a59eb-6472-4f07-937e-c2bbf2f9329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation (nettoyage et uniformisation) des valeurs textuelles\n",
    "# Pour products_df\n",
    "products_df['Department'] = products_df['Department'].str.strip().str.title()\n",
    "products_df['Sub-Category'] = products_df['Sub-Category'].str.strip().str.title()\n",
    "products_df['Product Name'] = products_df['Product Name'].str.strip()\n",
    "\n",
    "# Pour customers_df\n",
    "customers_df['Segment'] = customers_df['Segment'].str.strip().str.title()\n",
    "customers_df['Customer Name'] = customers_df['Customer Name'].str.strip()\n",
    "\n",
    "# Pour addresses_df\n",
    "addresses_df['City'] = addresses_df['City'].str.strip().str.title()\n",
    "addresses_df['State'] = addresses_df['State'].str.strip().str.title()\n",
    "addresses_df['Region'] = addresses_df['Region'].str.strip().str.title()\n",
    "addresses_df['Country'] = addresses_df['Country'].str.strip().str.title()\n",
    "\n",
    "# Pour departments_df\n",
    "departments_df['Department'] = departments_df['Department'].str.strip().str.title()\n",
    "departments_df['City'] = departments_df['City'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04aad2c8-a7cd-47f2-b9c0-70f109f7c61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Données après nettoyage ===\n",
      "addresses_df shape: (4910, 7)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "customers_df shape: (793, 3)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "departments_df shape: (3, 3)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "order_details_df shape: (9993, 5)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "orders_df shape: (5009, 5)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "products_df shape: (1862, 4)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n"
     ]
    }
   ],
   "source": [
    "# Vérification des données après nettoyage\n",
    "print(\"\\n=== Données après nettoyage ===\")\n",
    "for df_name, df in [(\"addresses_df\", addresses_df), \n",
    "                    (\"customers_df\", customers_df),\n",
    "                    (\"departments_df\", departments_df),\n",
    "                    (\"order_details_df\", order_details_df),\n",
    "                    (\"orders_df\", orders_df),\n",
    "                    (\"products_df\", products_df)]:\n",
    "    print(f\"{df_name} shape: {df.shape}\")\n",
    "    print(f\"Valeurs manquantes: {df.isnull().sum().sum()}\")\n",
    "    print(f\"Doublons: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9081161-bf42-4974-8e6f-8365dcd55f7c",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
