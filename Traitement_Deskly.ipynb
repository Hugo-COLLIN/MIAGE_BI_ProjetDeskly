{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "196ba1cc-cc51-493b-ab75-e2cc77086a85",
   "metadata": {},
   "source": [
    "# T1 - Reprise du modèle défini à la partie 1\n",
    "\n",
    "Notre modèle dimensionnel comprend :\n",
    "- 2 tables de faits : FACT_SALES et FACT_INVENTORY\n",
    "- 5 dimensions : DIM_TIME, DIM_PRODUCT, DIM_CUSTOMER, DIM_GEOGRAPHY, DIM_DEPARTMENT\n",
    "\n",
    "Vérification de la faisabilité avec les données disponibles :\n",
    "- Pour FACT_SALES : Nous avons orders.csv et order_details.csv qui contiennent les données nécessaires\n",
    "- Pour FACT_INVENTORY : Nous devrons dériver cette table à partir des ventes et des capacités de stockage\n",
    "- Pour les dimensions : Nous avons les fichiers correspondants (customers.csv, products.csv, etc.)\n",
    "\n",
    "Le modèle est donc réalisable avec les données disponibles. Certaines mesures devront être calculées ou estimées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fb29a-964f-4d8c-aaeb-8578848a3477",
   "metadata": {},
   "source": [
    "# T2 - Importation des fichiers CSV et inspection des structures\n",
    "Commençons par importer les fichiers CSV et examiner leur structure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852bba07-1d76-471c-8245-1a5c4b0e8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299cc651-ed98-47dc-813c-01a31434cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des fichiers CSV\n",
    "addresses_df = pd.read_csv('data/addresses.csv')\n",
    "customers_df = pd.read_csv('data/customers.csv')\n",
    "departments_df = pd.read_csv('data/departments.csv')\n",
    "order_details_df = pd.read_csv('data/order_details.csv')\n",
    "orders_df = pd.read_csv('data/orders.csv')\n",
    "products_df = pd.read_csv('data/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4487c9-f24f-4e03-a306-16d89f346d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Aperçu de addresses_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4910 entries, 0 to 4909\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Address ID   4910 non-null   object\n",
      " 1   Customer ID  4910 non-null   object\n",
      " 2   Country      4910 non-null   object\n",
      " 3   City         4910 non-null   object\n",
      " 4   State        4910 non-null   object\n",
      " 5   Postal Code  4910 non-null   int64 \n",
      " 6   Region       4910 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 268.6+ KB\n",
      "None\n",
      "       Address ID Customer ID        Country             City           State  \\\n",
      "0  CG-12520_42420    CG-12520  United States        Henderson        Kentucky   \n",
      "1  DV-13045_90036    DV-13045  United States      Los Angeles      California   \n",
      "2  SO-20335_33311    SO-20335  United States  Fort Lauderdale         Florida   \n",
      "3  BH-11710_90032    BH-11710  United States      Los Angeles      California   \n",
      "4  AA-10480_28027    AA-10480  United States          Concord  North Carolina   \n",
      "\n",
      "   Postal Code Region  \n",
      "0        42420  South  \n",
      "1        90036   West  \n",
      "2        33311  South  \n",
      "3        90032   West  \n",
      "4        28027  South  \n",
      "\n",
      "=== Aperçu de customers_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 793 entries, 0 to 792\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Customer ID    793 non-null    object\n",
      " 1   Customer Name  793 non-null    object\n",
      " 2   Segment        793 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 18.7+ KB\n",
      "None\n",
      "  Customer ID    Customer Name    Segment\n",
      "0    CG-12520      Claire Gute   Consumer\n",
      "1    DV-13045  Darrin Van Huff  Corporate\n",
      "2    SO-20335   Sean O'Donnell   Consumer\n",
      "3    BH-11710  Brosina Hoffman   Consumer\n",
      "4    AA-10480     Andrew Allen   Consumer\n",
      "\n",
      "=== Aperçu de departments_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Department        3 non-null      object\n",
      " 1   City              3 non-null      object\n",
      " 2   Storage Capacity  3 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 204.0+ bytes\n",
      "None\n",
      "        Department           City  Storage Capacity\n",
      "0        Furniture  New York City              3003\n",
      "1  Office Supplies  San Francisco              4043\n",
      "2       Technology   Philadelphia              2257\n",
      "\n",
      "=== Aperçu de order_details_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9993 entries, 0 to 9992\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Order ID    9993 non-null   object \n",
      " 1   Product ID  9993 non-null   object \n",
      " 2   Sales       9993 non-null   float64\n",
      " 3   Quantity    9993 non-null   int64  \n",
      " 4   Profit      9993 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 390.5+ KB\n",
      "None\n",
      "         Order ID       Product ID   Sales  Quantity  Profit\n",
      "0  CA-2016-152156  FUR-BO-10001798  261.96         2   41.91\n",
      "1  CA-2016-152156  FUR-CH-10000454  731.94         3  219.58\n",
      "2  CA-2016-138688  OFF-LA-10000240   14.62         2    6.87\n",
      "3  US-2015-108966  FUR-TA-10000577  957.58         5 -383.03\n",
      "4  US-2015-108966  OFF-ST-10000760   22.37         2    2.52\n",
      "\n",
      "=== Aperçu de orders_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5009 entries, 0 to 5008\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Order ID     5009 non-null   object\n",
      " 1   Order Date   5009 non-null   object\n",
      " 2   Ship Date    5009 non-null   object\n",
      " 3   Customer ID  5009 non-null   object\n",
      " 4   Address ID   5009 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 195.8+ KB\n",
      "None\n",
      "         Order ID  Order Date   Ship Date Customer ID      Address ID\n",
      "0  CA-2016-152156  2021-11-02  2021-11-05    CG-12520  CG-12520_42420\n",
      "1  CA-2016-138688  2021-06-06  2021-06-10    DV-13045  DV-13045_90036\n",
      "2  US-2015-108966  2020-10-04  2020-10-11    SO-20335  SO-20335_33311\n",
      "3  CA-2014-115812  2019-06-03  2019-06-08    BH-11710  BH-11710_90032\n",
      "4  CA-2017-114412  2022-04-09  2022-04-14    AA-10480  AA-10480_28027\n",
      "\n",
      "=== Aperçu de products_df ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1862 entries, 0 to 1861\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Product ID    1862 non-null   object\n",
      " 1   Department    1862 non-null   object\n",
      " 2   Sub-Category  1862 non-null   object\n",
      " 3   Product Name  1862 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 58.3+ KB\n",
      "None\n",
      "        Product ID       Department Sub-Category  \\\n",
      "0  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1  FUR-CH-10000454        Furniture       Chairs   \n",
      "2  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3  FUR-TA-10000577        Furniture       Tables   \n",
      "4  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name  \n",
      "0                  Bush Somerset Collection Bookcase  \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  \n",
      "2  Self-Adhesive Address Labels for Typewriters b...  \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  \n",
      "4                     Eldon Fold 'N Roll Cart System  \n"
     ]
    }
   ],
   "source": [
    "# Inspection des structures\n",
    "print(\"=== Aperçu de addresses_df ===\")\n",
    "print(addresses_df.info())\n",
    "print(addresses_df.head())\n",
    "print(\"\\n=== Aperçu de customers_df ===\")\n",
    "print(customers_df.info())\n",
    "print(customers_df.head())\n",
    "print(\"\\n=== Aperçu de departments_df ===\")\n",
    "print(departments_df.info())\n",
    "print(departments_df.head())\n",
    "print(\"\\n=== Aperçu de order_details_df ===\")\n",
    "print(order_details_df.info())\n",
    "print(order_details_df.head())\n",
    "print(\"\\n=== Aperçu de orders_df ===\")\n",
    "print(orders_df.info())\n",
    "print(orders_df.head())\n",
    "print(\"\\n=== Aperçu de products_df ===\")\n",
    "print(products_df.info())\n",
    "print(products_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431cd936-507c-416a-af3b-a24cc1e6857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Valeurs manquantes ===\n",
      "addresses_df ne contient pas de valeurs manquantes\n",
      "customers_df ne contient pas de valeurs manquantes\n",
      "departments_df ne contient pas de valeurs manquantes\n",
      "order_details_df ne contient pas de valeurs manquantes\n",
      "orders_df ne contient pas de valeurs manquantes\n",
      "products_df ne contient pas de valeurs manquantes\n"
     ]
    }
   ],
   "source": [
    "# Vérification des valeurs manquantes\n",
    "print(\"\\n=== Valeurs manquantes ===\")\n",
    "for df_name, df in [(\"addresses_df\", addresses_df), \n",
    "                    (\"customers_df\", customers_df),\n",
    "                    (\"departments_df\", departments_df),\n",
    "                    (\"order_details_df\", order_details_df),\n",
    "                    (\"orders_df\", orders_df),\n",
    "                    (\"products_df\", products_df)]:\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(f\"{df_name} contient des valeurs manquantes:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "    else:\n",
    "        print(f\"{df_name} ne contient pas de valeurs manquantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6565972-2339-4fce-9378-098f6cbc7272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Doublons ===\n",
      "addresses_df contient 0 doublons\n",
      "customers_df contient 0 doublons\n",
      "departments_df contient 0 doublons\n",
      "order_details_df contient 0 doublons\n",
      "orders_df contient 0 doublons\n",
      "products_df contient 0 doublons\n"
     ]
    }
   ],
   "source": [
    "# Vérification des doublons\n",
    "print(\"\\n=== Doublons ===\")\n",
    "for df_name, df in [(\"addresses_df\", addresses_df), \n",
    "                    (\"customers_df\", customers_df),\n",
    "                    (\"departments_df\", departments_df),\n",
    "                    (\"order_details_df\", order_details_df),\n",
    "                    (\"orders_df\", orders_df),\n",
    "                    (\"products_df\", products_df)]:\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"{df_name} contient {duplicates} doublons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "713f4e26-ce59-416a-af57-2577773f4f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Types de données ===\n",
      "addresses_df types:\n",
      "Address ID     object\n",
      "Customer ID    object\n",
      "Country        object\n",
      "City           object\n",
      "State          object\n",
      "Postal Code     int64\n",
      "Region         object\n",
      "dtype: object\n",
      "customers_df types:\n",
      "Customer ID      object\n",
      "Customer Name    object\n",
      "Segment          object\n",
      "dtype: object\n",
      "departments_df types:\n",
      "Department          object\n",
      "City                object\n",
      "Storage Capacity     int64\n",
      "dtype: object\n",
      "order_details_df types:\n",
      "Order ID       object\n",
      "Product ID     object\n",
      "Sales         float64\n",
      "Quantity        int64\n",
      "Profit        float64\n",
      "dtype: object\n",
      "orders_df types:\n",
      "Order ID               object\n",
      "Order Date     datetime64[ns]\n",
      "Ship Date      datetime64[ns]\n",
      "Customer ID            object\n",
      "Address ID             object\n",
      "dtype: object\n",
      "products_df types:\n",
      "Product ID      object\n",
      "Department      object\n",
      "Sub-Category    object\n",
      "Product Name    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Vérification des types de données\n",
    "print(\"\\n=== Types de données ===\")\n",
    "for df_name, df in [(\"addresses_df\", addresses_df), \n",
    "                    (\"customers_df\", customers_df),\n",
    "                    (\"departments_df\", departments_df),\n",
    "                    (\"order_details_df\", order_details_df),\n",
    "                    (\"orders_df\", orders_df),\n",
    "                    (\"products_df\", products_df)]:\n",
    "    print(f\"{df_name} types:\")\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b30758-8769-40f3-92a9-9a3ff65ebcc6",
   "metadata": {},
   "source": [
    "Après cette inspection, voici ce que nous pouvons relever :\n",
    "- Contrairement à nos suppositions, aucun des dataframes ne contient de valeurs manquantes, ce qui signifie que les données sont d'excellente qualité.\n",
    "- Aucun des dataframes ne contient de doublons, ce qui simplifie le processus de nettoyage.\n",
    "- Les dates dans orders_df (Order Date, Ship Date) sont au format string (object) et doivent être converties en format datetime pour permettre des opérations temporelles.\n",
    "- Les autres types de données semblent appropriés (les valeurs numériques sont déjà en int64 ou float64)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db80223-11a4-404d-b075-c15a024b5f5b",
   "metadata": {},
   "source": [
    "# T3 - Nettoyage des données\n",
    "Maintenant, procédons au nettoyage des données pour chaque dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfdff917-4ae2-4f20-8945-4a3ce5e5606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification et traitement des valeurs manquantes (il ne semble pas y en avoir, mais on ne sait jamais)\n",
    "# Pour addresses_df\n",
    "if addresses_df.isnull().sum().sum() > 0: # le premier .sum() donne le nombre de isNull par colonne, le second fait la somme de ces isNull\n",
    "    # Remplir les valeurs manquantes ou supprimer les lignes selon le contexte\n",
    "    addresses_df = addresses_df.dropna(subset=['Customer ID', 'City', 'State', 'Region'])\n",
    "    # Pour les autres colonnes, on peut remplir avec des valeurs par défaut\n",
    "    addresses_df['Postal Code'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Pour customers_df\n",
    "if customers_df.isnull().sum().sum() > 0:\n",
    "    # Les informations client doivent être complètes pour être exploitables, donc on supprime les lignes avec des valeurs manquantes\n",
    "    customers_df = customers_df.dropna()\n",
    "\n",
    "# Pour order_details_df\n",
    "if order_details_df.isnull().sum().sum() > 0:\n",
    "    # Vérifier les colonnes avec des valeurs manquantes\n",
    "    # Pour les valeurs numériques, on peut remplacer par 0 ou la moyenne\n",
    "    order_details_df['Quantity'].fillna(0, inplace=True)\n",
    "    order_details_df['Sales'].fillna(0, inplace=True)\n",
    "    order_details_df['Profit'].fillna(0, inplace=True)\n",
    "    # Supprimer les lignes où Product ID est manquant\n",
    "    order_details_df = order_details_df.dropna(subset=['Product ID'])\n",
    "\n",
    "# Pour products_df\n",
    "if products_df.isnull().sum().sum() > 0:\n",
    "    # Les informations produit sont essentielles, donc on supprime les lignes avec des valeurs manquantes\n",
    "    products_df = products_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db949f6c-850e-4b33-84cf-81dee560e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des doublons (les outputs de T2 n'en montrent pas, mais on ne sait jamais)\n",
    "addresses_df = addresses_df.drop_duplicates()\n",
    "customers_df = customers_df.drop_duplicates()\n",
    "departments_df = departments_df.drop_duplicates()\n",
    "order_details_df = order_details_df.drop_duplicates()\n",
    "orders_df = orders_df.drop_duplicates()\n",
    "products_df = products_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54e5f325-d77e-417d-a484-546def4d239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des dates dans orders_df\n",
    "orders_df['Order Date'] = pd.to_datetime(orders_df['Order Date'])\n",
    "orders_df['Ship Date'] = pd.to_datetime(orders_df['Ship Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "349a59eb-6472-4f07-937e-c2bbf2f9329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation (nettoyage et uniformisation) des valeurs textuelles\n",
    "# Pour products_df\n",
    "products_df['Department'] = products_df['Department'].str.strip().str.title()\n",
    "products_df['Sub-Category'] = products_df['Sub-Category'].str.strip().str.title()\n",
    "products_df['Product Name'] = products_df['Product Name'].str.strip()\n",
    "\n",
    "# Pour customers_df\n",
    "customers_df['Segment'] = customers_df['Segment'].str.strip().str.title()\n",
    "customers_df['Customer Name'] = customers_df['Customer Name'].str.strip()\n",
    "\n",
    "# Pour addresses_df\n",
    "addresses_df['City'] = addresses_df['City'].str.strip().str.title()\n",
    "addresses_df['State'] = addresses_df['State'].str.strip().str.title()\n",
    "addresses_df['Region'] = addresses_df['Region'].str.strip().str.title()\n",
    "addresses_df['Country'] = addresses_df['Country'].str.strip().str.title()\n",
    "\n",
    "# Pour departments_df\n",
    "departments_df['Department'] = departments_df['Department'].str.strip().str.title()\n",
    "departments_df['City'] = departments_df['City'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04aad2c8-a7cd-47f2-b9c0-70f109f7c61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Données après nettoyage ===\n",
      "addresses_df shape: (4910, 7)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "customers_df shape: (793, 3)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "departments_df shape: (3, 3)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "order_details_df shape: (9993, 5)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "orders_df shape: (5009, 5)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n",
      "products_df shape: (1862, 4)\n",
      "Valeurs manquantes: 0\n",
      "Doublons: 0\n"
     ]
    }
   ],
   "source": [
    "# Vérification des données après nettoyage\n",
    "print(\"\\n=== Données après nettoyage ===\")\n",
    "for df_name, df in [(\"addresses_df\", addresses_df), \n",
    "                    (\"customers_df\", customers_df),\n",
    "                    (\"departments_df\", departments_df),\n",
    "                    (\"order_details_df\", order_details_df),\n",
    "                    (\"orders_df\", orders_df),\n",
    "                    (\"products_df\", products_df)]:\n",
    "    print(f\"{df_name} shape: {df.shape}\")\n",
    "    print(f\"Valeurs manquantes: {df.isnull().sum().sum()}\")\n",
    "    print(f\"Doublons: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9081161-bf42-4974-8e6f-8365dcd55f7c",
   "metadata": {},
   "source": [
    "# T4 - Réalisation des jointures nécessaires\n",
    "Maintenant, créons les tables dimensionnelles et les tables de faits conformément à notre modèle en étoile :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ead27c7b-0cb0-48a3-b36d-2fc0c854b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de DIM_TIME\n",
    "def create_dim_time(orders_df):\n",
    "    # Extraire toutes les dates uniques des commandes et expéditions\n",
    "    all_dates = pd.concat([orders_df['Order Date'], orders_df['Ship Date']]).drop_duplicates().sort_values()\n",
    "    \n",
    "    # Créer le dataframe de dimension temporelle\n",
    "    dim_time = pd.DataFrame({\n",
    "        'date': all_dates,\n",
    "        'day_of_week': all_dates.dt.day_name(),\n",
    "        'month': all_dates.dt.month_name(),\n",
    "        'quarter': all_dates.dt.quarter,\n",
    "        'year': all_dates.dt.year\n",
    "    })\n",
    "    \n",
    "    # Ajouter la saison\n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Fall'\n",
    "    \n",
    "    dim_time['season'] = dim_time['date'].dt.month.apply(get_season)\n",
    "    \n",
    "    # Ajouter une clé primaire\n",
    "    dim_time['time_id'] = range(1, len(dim_time) + 1)\n",
    "    \n",
    "    return dim_time\n",
    "\n",
    "# Création de DIM_PRODUCT\n",
    "def create_dim_product(products_df):\n",
    "    # Copier les données produits\n",
    "    dim_product = products_df.copy()\n",
    "    \n",
    "    # Renommer les colonnes pour correspondre au modèle\n",
    "    dim_product = dim_product.rename(columns={\n",
    "        'Product ID': 'product_id',\n",
    "        'Product Name': 'product_name',\n",
    "        'Sub-Category': 'sub_category',\n",
    "        'Department': 'department'\n",
    "    })\n",
    "    \n",
    "    return dim_product\n",
    "\n",
    "# Création de DIM_CUSTOMER\n",
    "def create_dim_customer(customers_df, orders_df):\n",
    "    # Copier les données clients\n",
    "    dim_customer = customers_df.copy()\n",
    "    \n",
    "    # Calculer la date de première commande pour chaque client\n",
    "    first_orders = orders_df.groupby('Customer ID')['Order Date'].min().reset_index()\n",
    "    first_orders = first_orders.rename(columns={'Order Date': 'first_order_date'})\n",
    "    \n",
    "    # Calculer le nombre de commandes par client\n",
    "    order_counts = orders_df.groupby('Customer ID').size().reset_index(name='order_count')\n",
    "    \n",
    "    # Joindre ces informations à la dimension client\n",
    "    dim_customer = dim_customer.merge(first_orders, on='Customer ID', how='left')\n",
    "    dim_customer = dim_customer.merge(order_counts, on='Customer ID', how='left')\n",
    "    \n",
    "    # Renommer les colonnes pour correspondre au modèle\n",
    "    dim_customer = dim_customer.rename(columns={\n",
    "        'Customer ID': 'customer_id',\n",
    "        'Customer Name': 'customer_name',\n",
    "        'Segment': 'segment'\n",
    "    })\n",
    "    \n",
    "    return dim_customer\n",
    "\n",
    "# Création de DIM_GEOGRAPHY\n",
    "def create_dim_geography(addresses_df):\n",
    "    # Copier les données d'adresses\n",
    "    dim_geography = addresses_df.copy()\n",
    "    \n",
    "    # Renommer les colonnes pour correspondre au modèle\n",
    "    dim_geography = dim_geography.rename(columns={\n",
    "        'Address ID': 'geography_id',\n",
    "        'City': 'city',\n",
    "        'State': 'state',\n",
    "        'Region': 'region',\n",
    "        'Country': 'country',\n",
    "        'Postal Code': 'postal_code'\n",
    "    })\n",
    "    \n",
    "    # Supprimer la colonne Customer ID qui n'est pas nécessaire dans cette dimension\n",
    "    dim_geography = dim_geography.drop(columns=['Customer ID'])\n",
    "    \n",
    "    return dim_geography\n",
    "\n",
    "# Création de DIM_DEPARTMENT\n",
    "def create_dim_department(departments_df):\n",
    "    # Copier les données de départements\n",
    "    dim_department = departments_df.copy()\n",
    "    \n",
    "    # Renommer les colonnes pour correspondre au modèle\n",
    "    dim_department = dim_department.rename(columns={\n",
    "        'Department': 'department_name',\n",
    "        'City': 'city',\n",
    "        'Storage Capacity': 'storage_capacity'\n",
    "    })\n",
    "    \n",
    "    # Ajouter une clé primaire\n",
    "    dim_department['department_id'] = range(1, len(dim_department) + 1)\n",
    "    \n",
    "    return dim_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9a8a0e6-28df-49fd-a236-bc7f52fe4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de FACT_SALES\n",
    "def create_fact_sales(orders_df, order_details_df, dim_time, dim_customer, dim_product, dim_geography):\n",
    "    # Joindre les commandes et les détails de commande\n",
    "    fact_sales = orders_df.merge(order_details_df, on='Order ID', how='inner')\n",
    "    \n",
    "    # Calculer le délai de livraison en jours\n",
    "    fact_sales['delivery_time'] = (fact_sales['Ship Date'] - fact_sales['Order Date']).dt.days\n",
    "    \n",
    "    # Créer des mappings pour les clés étrangères\n",
    "    # Pour la dimension temps, nous avons besoin de mapper les dates de commande\n",
    "    time_mapping = pd.Series(dim_time['time_id'].values, index=dim_time['date']).to_dict()\n",
    "    \n",
    "    # Ajouter les clés étrangères\n",
    "    fact_sales['time_id'] = fact_sales['Order Date'].map(time_mapping)\n",
    "    \n",
    "    # Renommer les colonnes pour correspondre au modèle\n",
    "    fact_sales = fact_sales.rename(columns={\n",
    "        'Order ID': 'order_id',\n",
    "        'Customer ID': 'customer_id',\n",
    "        'Product ID': 'product_id',\n",
    "        'Address ID': 'geography_id',\n",
    "        'Quantity': 'quantity',\n",
    "        'Sales': 'sales',\n",
    "        'Profit': 'profit'\n",
    "    })\n",
    "    \n",
    "    # Sélectionner uniquement les colonnes nécessaires\n",
    "    fact_sales = fact_sales[['order_id', 'time_id', 'customer_id', 'product_id', 'geography_id', \n",
    "                             'quantity', 'sales', 'profit', 'delivery_time']]\n",
    "    \n",
    "    return fact_sales\n",
    "\n",
    "# Création de FACT_INVENTORY\n",
    "def create_fact_inventory(fact_sales, dim_product, dim_department, dim_time):\n",
    "    # Agréger les ventes par produit et par période\n",
    "    sales_agg = fact_sales.groupby(['time_id', 'product_id']).agg({\n",
    "        'quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Créer un mapping entre les produits et leurs départements\n",
    "    product_dept_mapping = dim_product.set_index('product_id')['department'].to_dict()\n",
    "    \n",
    "    # Ajouter le département à chaque ligne\n",
    "    sales_agg['department'] = sales_agg['product_id'].map(product_dept_mapping)\n",
    "    \n",
    "    # Créer un mapping entre les noms de département et leurs IDs\n",
    "    dept_id_mapping = dim_department.set_index('department_name')['department_id'].to_dict()\n",
    "    \n",
    "    # Ajouter l'ID du département\n",
    "    sales_agg['department_id'] = sales_agg['department'].map(dept_id_mapping)\n",
    "    \n",
    "    # Créer un mapping pour la capacité de stockage par département\n",
    "    storage_capacity_mapping = dim_department.set_index('department_id')['storage_capacity'].to_dict()\n",
    "    \n",
    "    # Ajouter la capacité de stockage\n",
    "    sales_agg['storage_capacity'] = sales_agg['department_id'].map(storage_capacity_mapping)\n",
    "    \n",
    "    # Calculer un taux d'utilisation estimé (simplifié)\n",
    "    # Nous utilisons la quantité vendue divisée par la capacité de stockage comme approximation\n",
    "    sales_agg['utilization_rate'] = sales_agg['quantity'] / sales_agg['storage_capacity']\n",
    "    \n",
    "    # Renommer pour correspondre au modèle\n",
    "    fact_inventory = sales_agg.rename(columns={\n",
    "        'quantity': 'quantity_sold'\n",
    "    })\n",
    "    \n",
    "    # Ajouter un ID unique\n",
    "    fact_inventory['inventory_id'] = range(1, len(fact_inventory) + 1)\n",
    "    \n",
    "    # Sélectionner uniquement les colonnes nécessaires\n",
    "    fact_inventory = fact_inventory[['inventory_id', 'time_id', 'product_id', 'department_id', \n",
    "                                     'quantity_sold', 'storage_capacity', 'utilization_rate']]\n",
    "    \n",
    "    return fact_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7767a99b-9e75-4e6a-9222-f8620c231e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tables dimensionnelles créées ===\n",
      "DIM_TIME: (1434, 7)\n",
      "DIM_PRODUCT: (1862, 4)\n",
      "DIM_CUSTOMER: (793, 5)\n",
      "DIM_GEOGRAPHY: (4910, 6)\n",
      "DIM_DEPARTMENT: (3, 4)\n",
      "\n",
      "=== Tables de faits créées ===\n",
      "FACT_SALES: (9993, 9)\n",
      "FACT_INVENTORY: (9955, 7)\n",
      "\n",
      "=== Aperçu de DIM_TIME ===\n",
      "           date day_of_week     month  quarter  year  season  time_id\n",
      "3952 2018-12-28      Friday  December        4  2018  Winter        1\n",
      "343  2018-12-29    Saturday  December        4  2018  Winter        2\n",
      "854  2018-12-30      Sunday  December        4  2018  Winter        3\n",
      "2647 2018-12-31      Monday  December        4  2018  Winter        4\n",
      "3796 2019-01-01     Tuesday   January        1  2019  Winter        5\n",
      "\n",
      "=== Aperçu de FACT_SALES ===\n",
      "         order_id  time_id customer_id       product_id    geography_id  \\\n",
      "0  CA-2016-152156     1011    CG-12520  FUR-BO-10001798  CG-12520_42420   \n",
      "1  CA-2016-152156     1011    CG-12520  FUR-CH-10000454  CG-12520_42420   \n",
      "2  CA-2016-138688      863    DV-13045  OFF-LA-10000240  DV-13045_90036   \n",
      "3  US-2015-108966      623    SO-20335  FUR-TA-10000577  SO-20335_33311   \n",
      "4  US-2015-108966      623    SO-20335  OFF-ST-10000760  SO-20335_33311   \n",
      "\n",
      "   quantity   sales  profit  delivery_time  \n",
      "0         2  261.96   41.91              3  \n",
      "1         3  731.94  219.58              3  \n",
      "2         2   14.62    6.87              4  \n",
      "3         5  957.58 -383.03              7  \n",
      "4         2   22.37    2.52              7  \n",
      "\n",
      "=== Aperçu de FACT_INVENTORY ===\n",
      "   inventory_id  time_id       product_id  department_id  quantity_sold  \\\n",
      "0             1        1  OFF-PA-10000174              2              2   \n",
      "1             2        2  OFF-BI-10004094              2              2   \n",
      "2             3        2  OFF-LA-10003223              2              3   \n",
      "3             4        2  OFF-ST-10002743              2              3   \n",
      "4             5        3  OFF-AR-10003478              2              3   \n",
      "\n",
      "   storage_capacity  utilization_rate  \n",
      "0              4043          0.000495  \n",
      "1              4043          0.000495  \n",
      "2              4043          0.000742  \n",
      "3              4043          0.000742  \n",
      "4              4043          0.000742  \n"
     ]
    }
   ],
   "source": [
    "# Création des dimensions\n",
    "dim_time = create_dim_time(orders_df)\n",
    "dim_product = create_dim_product(products_df)\n",
    "dim_customer = create_dim_customer(customers_df, orders_df)\n",
    "dim_geography = create_dim_geography(addresses_df)\n",
    "dim_department = create_dim_department(departments_df)\n",
    "\n",
    "# Création des tables de faits\n",
    "fact_sales = create_fact_sales(orders_df, order_details_df, dim_time, dim_customer, dim_product, dim_geography)\n",
    "fact_inventory = create_fact_inventory(fact_sales, dim_product, dim_department, dim_time)\n",
    "\n",
    "# Vérification des tables créées\n",
    "print(\"\\n=== Tables dimensionnelles créées ===\")\n",
    "print(f\"DIM_TIME: {dim_time.shape}\")\n",
    "print(f\"DIM_PRODUCT: {dim_product.shape}\")\n",
    "print(f\"DIM_CUSTOMER: {dim_customer.shape}\")\n",
    "print(f\"DIM_GEOGRAPHY: {dim_geography.shape}\")\n",
    "print(f\"DIM_DEPARTMENT: {dim_department.shape}\")\n",
    "\n",
    "print(\"\\n=== Tables de faits créées ===\")\n",
    "print(f\"FACT_SALES: {fact_sales.shape}\")\n",
    "print(f\"FACT_INVENTORY: {fact_inventory.shape}\")\n",
    "\n",
    "# Afficher un aperçu des tables\n",
    "print(\"\\n=== Aperçu de DIM_TIME ===\")\n",
    "print(dim_time.head())\n",
    "print(\"\\n=== Aperçu de FACT_SALES ===\")\n",
    "print(fact_sales.head())\n",
    "print(\"\\n=== Aperçu de FACT_INVENTORY ===\")\n",
    "print(fact_inventory.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d666dca-8af3-4216-bf5e-ff4ef850081b",
   "metadata": {},
   "source": [
    "# T5 - Enregistrement des tables finales au format CSV\n",
    "Maintenant, enregistrons toutes nos tables au format CSV pour pouvoir les importer dans Power BI :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db030e93-e1b0-4561-a06b-504607d72ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toutes les tables ont été enregistrées dans le dossier 'output_tables'\n"
     ]
    }
   ],
   "source": [
    "# Création d'un dossier pour stocker les fichiers si nécessaire\n",
    "import os\n",
    "if not os.path.exists('output_tables'):\n",
    "    os.makedirs('output_tables')\n",
    "\n",
    "# Enregistrement des tables dimensionnelles\n",
    "dim_time.to_csv('output_tables/dim_time.csv', index=False)\n",
    "dim_product.to_csv('output_tables/dim_product.csv', index=False)\n",
    "dim_customer.to_csv('output_tables/dim_customer.csv', index=False)\n",
    "dim_geography.to_csv('output_tables/dim_geography.csv', index=False)\n",
    "dim_department.to_csv('output_tables/dim_department.csv', index=False)\n",
    "\n",
    "# Enregistrement des tables de faits\n",
    "fact_sales.to_csv('output_tables/fact_sales.csv', index=False)\n",
    "fact_inventory.to_csv('output_tables/fact_inventory.csv', index=False)\n",
    "\n",
    "print(\"Toutes les tables ont été enregistrées dans le dossier 'output_tables'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e4e0e-69e9-4203-a4da-e94160f9cb57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
